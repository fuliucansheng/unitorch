[core/cli]
task_name = core/task/deepspeed/supervised
from_ckpt_dir = ./cache
cache_dir = ./cache
output_folder = ./videos
train_file = ./train.tsv
dev_file = ./dev.tsv
test_file = ./test.tsv

# model
[core/model/diffusers/peft/lora/text2video/wan]
pretrained_name = wan-v2.1-t2v-1.3b

# dataset
[core/dataset/ast]
names = ['text', 'video']

[core/dataset/ast/train]
data_files = ${core/cli:train_file}
preprocess_functions = [
    'core/process/diffusion/wan/text2video(text, core/process/video/read(video))'
  ]

[core/dataset/ast/dev]
data_files = ${core/cli:dev_file}
preprocess_functions = [
    'core/process/diffusion/wan/text2video(text, core/process/video/read(video))'
  ]

[core/dataset/ast/test]
names = ['text']
data_files = ${core/cli:test_file}
preprocess_functions = [
    'core/process/diffusion/wan/text2video/inputs(text)',
  ]

# process
[core/process/diffusion/wan]
pretrained_name = wan-v2.1-t2v-1.3b
max_seq_length = 77
video_size = (832, 480)

[core/process/video]
http_url = http://0.0.0.0:11230/?file={0}

[core/process/diffusion]
output_folder = ${core/cli:output_folder}

# task
[core/task/deepspeed/supervised]
config_path = https://raw.githubusercontent.com/fuliucansheng/unitorch/master/examples/configs/deepspeed/adamw.bf16.json
model = core/model/diffusers/peft/lora/text2video/wan
dataset = core/dataset/ast
score_fn = core/score/loss
monitor_fns = ['core/score/loss']
output_header = ['text']
postprocess_fn = core/postprocess/diffusion/video
writer = core/writer/csv

from_ckpt_dir = ${core/cli:from_ckpt_dir}
to_ckpt_dir = ${core/cli:cache_dir}
output_path = ${core/cli:cache_dir}/output.txt

num_workers = 16
log_freq = 10

train_batch_size = 1
dev_batch_size = 1
test_batch_size = 2
