{
	"train_micro_batch_size_per_gpu": 16,
	"prescale_gradients": false,
	"zero_optimization": {
		"stage": 2
	},
	"optimizer": {
		"type": "AdamW",
		"params": {
			"lr": 5e-6,
			"betas": [
				0.9,
				0.999
			],
			"weight_decay": 0.0
		}
	},
	"gradient_clipping": 1.0,

	"wall_clock_breakdown": false,

	"fp16": {
		"enabled": false,
		"loss_scale": 0
	},
	"scheduler": {
		"type": "WarmupLR",
		"params": {
			"warmup_min_lr": 0,
			"warmup_max_lr": 0.00003,
			"warmup_num_steps": 3000
		}
	}
}
